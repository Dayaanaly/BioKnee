{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dayaanaly/BioKnee/blob/Dayana/U_Net_BioKnee_DP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmetación automatica con U-Net**"
      ],
      "metadata": {
        "id": "evkDEhyul4LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynrrd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onRK6diXBoJZ",
        "outputId": "8b678eed-7935-4652-af90-f8ba78890e07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynrrd\n",
            "  Downloading pynrrd-1.1.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from pynrrd) (2.0.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pynrrd) (4.13.2)\n",
            "Downloading pynrrd-1.1.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pynrrd\n",
            "Successfully installed pynrrd-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar el drive"
      ],
      "metadata": {
        "id": "9N8RNtciPzgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QQTH2G64GZGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8595ac-95ae-46c4-b45a-baf620daa8fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerías y preprocesamiento"
      ],
      "metadata": {
        "id": "M_XoxvMnPehJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import cv2  # Para redimensionar imágenes .nrrd\n",
        "import nrrd  # Para cargar archivos .nrrd (si no lo tienes, instala con: !pip install pynrrd)\n",
        "\n",
        "# ================================\n",
        "# Parámetros y directorios para rótula\n",
        "# ================================\n",
        "# Directorios de imágenes y máscaras\n",
        "image_dir = '/content/drive/MyDrive/Equipo Trifuerza/Datos/Data set grises/Dataset mascaras 2D'\n",
        "mask_dir  = '/content/drive/MyDrive/Equipo Trifuerza/Datos/Data set grises/Mascaras-2D'\n",
        "\n",
        "# Parámetros de la imagen y segmentación\n",
        "IMG_HEIGHT = 320\n",
        "IMG_WIDTH = 224\n",
        "IMG_CHANNELS = 1      # Imágenes en escala de grises\n",
        "NUM_CLASSES = 4       # Ejemplo: Rótula, tibia, fémur, fondo\n",
        "batch_size = 8\n",
        "\n",
        "# Filtrar archivos válidos (.nrrd y .bmp)\n",
        "valid_extensions = ('.nrrd', '.bmp')\n",
        "image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(valid_extensions)])\n",
        "mask_files  = sorted([f for f in os.listdir(mask_dir) if f.lower().endswith(valid_extensions)])\n",
        "assert len(image_files) == len(mask_files), \"La cantidad de imágenes y máscaras debe ser la misma\"\n",
        "\n",
        "# ================================\n",
        "# Función personalizada para cargar imágenes\n",
        "# ================================\n",
        "def load_image_custom(filepath, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='grayscale'):\n",
        "    ext = os.path.splitext(filepath)[1].lower()\n",
        "    if ext == '.nrrd':\n",
        "        # Cargar usando la librería nrrd\n",
        "        img_data, header = nrrd.read(filepath)\n",
        "        # Dependiendo del color_mode, procesamos la imagen:\n",
        "        if color_mode == 'grayscale':\n",
        "            # Si la imagen es a color, convertirla a escala de grises (promediando canales)\n",
        "            if img_data.ndim == 3 and img_data.shape[-1] > 1:\n",
        "                img_data = np.mean(img_data, axis=-1)\n",
        "            # Asegurarse de que la imagen sea 2D antes de redimensionar\n",
        "            # Redimensionar usando cv2 (cv2.resize requiere (ancho, alto))\n",
        "            img_resized = cv2.resize(img_data, (target_size[1], target_size[0]))\n",
        "            # Agregar la dimensión del canal\n",
        "            img_resized = np.expand_dims(img_resized, axis=-1)\n",
        "            return img_resized\n",
        "        elif color_mode == 'rgb':\n",
        "            # Si es color, se espera que la imagen tenga 3 canales\n",
        "            # En caso de tener una sola banda, se replicará\n",
        "            if img_data.ndim == 2:\n",
        "                img_data = np.stack((img_data,)*3, axis=-1)\n",
        "            img_resized = cv2.resize(img_data, (target_size[1], target_size[0]))\n",
        "            return img_resized\n",
        "        else:\n",
        "            raise ValueError(\"Modo de color no soportado: \" + color_mode)\n",
        "    else:\n",
        "        # Para otros formatos (.bmp), usamos load_img de Keras\n",
        "        return img_to_array(load_img(filepath, target_size=target_size, color_mode=color_mode))\n",
        "\n",
        "# ================================\n",
        "# Cargar y preprocesar imágenes y máscaras\n",
        "# ================================\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "for img_file, msk_file in zip(image_files, mask_files):\n",
        "    image_path = os.path.join(image_dir, img_file)\n",
        "    mask_path  = os.path.join(mask_dir, msk_file)\n",
        "\n",
        "    # Cargar la imagen y normalizar (valores entre 0 y 1)\n",
        "    img = load_image_custom(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='grayscale')\n",
        "    img = img.astype('float32') / 255.0\n",
        "\n",
        "    # Cargar la máscara (se espera que contenga índices de clase)\n",
        "    mask = load_image_custom(mask_path, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='grayscale')\n",
        "    mask = mask.astype(np.int64)\n",
        "    #Rotar la máscara 90 grados a la izquierda\n",
        "    mask = np.rot90(mask, k=3, axes=(0, 1))  # 90° horario\n",
        "    # Redimensiona la máscara para que tenga nuevamente el tamaño\n",
        "    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
        "    # VOLTEO HORIZONTAL para corregir el “espejo”\n",
        "    mask = np.fliplr(mask)\n",
        "    # Aseguramos (H, W, 1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    # Agragar la dimensión del canal para que la máscara tenga forma(alto,ancho,1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    images.append(img)\n",
        "    masks.append(mask)\n",
        "\n",
        "# Convertir listas a arrays de NumPy\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y validación (por ejemplo, 90% train, 10% val)\n",
        "images_train, images_val, masks_train, masks_val = train_test_split(\n",
        "    images, masks, test_size=0.1, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "_jhJPLgMPMIU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data aumentation\n"
      ],
      "metadata": {
        "id": "Q-hUZaQvPQ6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "# ================================\n",
        "# Crear generadores de datos con aumento (augmentation)\n",
        "# ================================\n",
        "data_gen_args = dict(\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "seed = 42\n",
        "\n",
        "train_image_generator = image_datagen.flow(\n",
        "    images_train, batch_size=batch_size, seed=seed\n",
        ")\n",
        "train_mask_generator = mask_datagen.flow(\n",
        "    masks_train, batch_size=batch_size, seed=seed\n",
        ")\n",
        "\n",
        "val_image_generator = image_datagen.flow(\n",
        "    images_val, batch_size=batch_size, seed=seed\n",
        ")\n",
        "val_mask_generator = mask_datagen.flow(\n",
        "    masks_val, batch_size=batch_size, seed=seed\n",
        ")\n",
        "\n",
        "def train_generator():\n",
        "    while True:\n",
        "        imgs = next(train_image_generator)  # Usar next() en lugar de .next()\n",
        "        msks = next(train_mask_generator)\n",
        "        yield (imgs, msks)\n",
        "\n",
        "def val_generator():\n",
        "    while True:\n",
        "        imgs = next(val_image_generator)\n",
        "        msks = next(val_mask_generator)\n",
        "        yield (imgs, msks)\n",
        "\n",
        "\n",
        "# (Opcional) Visualizar algunas imágenes y máscaras aumentadas\n",
        "batch = next(train_generator())\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(5):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(batch[0][i].squeeze(), cmap='gray')\n",
        "    plt.title(\"Imagen Aumentada\")\n",
        "    plt.axis('off')\n",
        "    plt.subplot(2, 5, i+6)\n",
        "    plt.imshow(batch[1][i].squeeze(), cmap='gray')\n",
        "    plt.title(\"Máscara Aumentada\")\n",
        "    plt.axis('off')\n",
        "plt.show() \"\"\""
      ],
      "metadata": {
        "id": "aiYaW5V3PTJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición U-Net multuclase y entrenamiento"
      ],
      "metadata": {
        "id": "Bm33bTghd04c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TMuF-YxL_zqd",
        "outputId": "3c2f96fd-bb57-4817-b966-fd8284b52394"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node Equal defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-8-f5aad004f4f8>\", line 73, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 84, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 490, in compute_metrics\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 334, in update_state\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 21, in update_state\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/metrics/reduction_metrics.py\", line 203, in update_state\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 240, in sparse_categorical_accuracy\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 2699, in equal\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 1235, in equal\n\nIncompatible shapes: [8,320,224] vs. [8,320,224,1,1]\n\t [[{{node Equal}}]] [Op:__inference_multi_step_on_iterator_19719]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f5aad004f4f8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Entrenamiento del modelo con EarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mimages_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mmasks_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Equal defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-8-f5aad004f4f8>\", line 73, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 84, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 490, in compute_metrics\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 334, in update_state\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 21, in update_state\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/metrics/reduction_metrics.py\", line 203, in update_state\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 240, in sparse_categorical_accuracy\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 2699, in equal\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 1235, in equal\n\nIncompatible shapes: [8,320,224] vs. [8,320,224,1,1]\n\t [[{{node Equal}}]] [Op:__inference_multi_step_on_iterator_19719]"
          ]
        }
      ],
      "source": [
        "# Definir la U-Net para segmentación multi‑clase\n",
        "# ================================\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "def U_net(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), num_classes=NUM_CLASSES):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Bloque Down 1\n",
        "    conv1 = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, padding='same', activation='relu')(conv1)\n",
        "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    # Bloque Down 2\n",
        "    conv2 = layers.Conv2D(128, 3, padding='same', activation='relu')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, padding='same', activation='relu')(conv2)\n",
        "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    # Bloque Down 3\n",
        "    conv3 = layers.Conv2D(256, 3, padding='same', activation='relu')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, padding='same', activation='relu')(conv3)\n",
        "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    # Bloque intermedio\n",
        "    conv4 = layers.Conv2D(512, 3, padding='same', activation='relu')(pool3)\n",
        "    conv4 = layers.Conv2D(512, 3, padding='same', activation='relu')(conv4)\n",
        "\n",
        "    # Up 1\n",
        "    up1 = layers.UpSampling2D((2, 2))(conv4)\n",
        "    concat1 = layers.concatenate([up1, conv3])\n",
        "    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(concat1)\n",
        "    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(conv5)\n",
        "\n",
        "    # Up 2\n",
        "    up2 = layers.UpSampling2D((2, 2))(conv5)\n",
        "    concat2 = layers.concatenate([up2, conv2])\n",
        "    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(concat2)\n",
        "    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(conv6)\n",
        "\n",
        "    # Up 3\n",
        "    up3 = layers.UpSampling2D((2, 2))(conv6)\n",
        "    concat3 = layers.concatenate([up3, conv1])\n",
        "    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(concat3)\n",
        "    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(conv7)\n",
        "\n",
        "    # Capa de salida: NUM_CLASSES canales con activación softmax\n",
        "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(conv7)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = U_net()\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "steps_per_epoch = len(images_train) // batch_size\n",
        "validation_steps = len(images_val) // batch_size\n",
        "\n",
        "# ================================\n",
        "# Entrenamiento\n",
        "# ================================\n",
        "\n",
        "#from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# EarlyStopping\n",
        "#early_stop = EarlyStopping(\n",
        "    #monitor='val_loss',         # Monitorea la pérdida en validación\n",
        "    #patience=5,                 # Número de épocas sin mejora antes de detener el entrenamiento\n",
        "    #restore_best_weights=True   # Restaura los mejores pesos obtenidos durante el entrenamiento\n",
        "#)\n",
        "\n",
        "# Entrenamiento del modelo con EarlyStopping\n",
        "history = model.fit(\n",
        "    images_train,\n",
        "    masks_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(images_val, masks_val),\n",
        "    epochs=1,                 # Número máximo de épocas\n",
        "    #callbacks=[early_stop]     # Añadido el callback aquí\n",
        ")\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "# Ruta personalizada en Drive\n",
        "model_path = '/content/drive/MyDrive/Equipo Trifuerza/Códigos fuentes/Modelos entrenados/U-Net_entrenada_prueba.h5'\n",
        "model.save(model_path)\n",
        "\n",
        "# ================================\n",
        "# Graficar curvas de entrenamiento\n",
        "# ================================\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Pérdida Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida Validación')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Evolución de la pérdida')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Exactitud Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Exactitud Validación')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Exactitud')\n",
        "plt.title('Evolución de la exactitud')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualización"
      ],
      "metadata": {
        "id": "HBt4EK9wS6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Visualización de predicciones\n",
        "# ================================\n",
        "\n",
        "# Elegir algunas imágenes del conjunto de validación\n",
        "num_samples = 5  # Número de imágenes a visualizar\n",
        "sample_images = images_val[:num_samples]\n",
        "sample_masks = masks_val[:num_samples]\n",
        "\n",
        "# Realizar predicciones\n",
        "preds = model.predict(sample_images)\n",
        "\n",
        "# Convertir las predicciones softmax a clases (argmax)\n",
        "preds_classes = np.argmax(preds, axis=-1)\n",
        "true_classes = np.squeeze(sample_masks, axis=-1)\n",
        "\n",
        "# Visualizar\n",
        "plt.figure(figsize=(15, num_samples * 3))\n",
        "for i in range(num_samples):\n",
        "    # Imagen original\n",
        "    plt.subplot(num_samples, 3, i*3 + 1)\n",
        "    plt.imshow(sample_images[i].squeeze(), cmap='gray')\n",
        "    plt.title('Imagen original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Máscara real\n",
        "    plt.subplot(num_samples, 3, i*3 + 2)\n",
        "    plt.imshow(true_classes[i], cmap='nipy_spectral', vmin=0, vmax=NUM_CLASSES-1)\n",
        "    plt.title('Máscara real')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Máscara predicha\n",
        "    plt.subplot(num_samples, 3, i*3 + 3)\n",
        "    plt.imshow(preds_classes[i], cmap='nipy_spectral', vmin=0, vmax=NUM_CLASSES-1)\n",
        "    plt.title('Predicción')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FC2iGbQgS5_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar la predicciones obtenidas"
      ],
      "metadata": {
        "id": "WYchk4NVREee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Crear carpeta en Drive si no existe\n",
        "save_dir = \"/content/drive/MyDrive/Equipo Trifuerza/Datos/Data set grises/Predicciones\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Guardar cada máscara predicha como .png\n",
        "for i in range(len(predicted_masks)):\n",
        "    mask = predicted_masks[i].squeeze().astype(np.uint8)\n",
        "    filename = f\"prediccion_{i}.png\"\n",
        "    save_path = os.path.join(save_dir, filename)\n",
        "    cv2.imwrite(save_path, mask)\n",
        "\n",
        "print(f\"Guardadas {len(predicted_masks)} máscaras predichas en: {save_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "MHAAQ_29RDRh",
        "outputId": "de0218b6-4c78-4e02-b25a-a388a5d8adff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predicted_masks' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2c8a25ffd8ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Guardar cada máscara predicha como .png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"prediccion_{i}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predicted_masks' is not defined"
          ]
        }
      ]
    }
  ]
}